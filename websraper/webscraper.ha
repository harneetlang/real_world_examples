/*
    Harneet Programming Language 
    File Name - webscraper.ha.
    Purpose - provides a detailed example of how to
        1. Perform Webscraping in Harneet Programming language
    Purposefuly verbose - so as to show all the functionalities of the language
*/

package main
import fmt
import http
import regex
import cast

fmt.Println("=== Harneet Web Scraping Examples ===")
fmt.Println("ğŸŒ Using HTTP module for requests and regex for HTML parsing")

// Test the scraper
var testUrl = "https://www.wikipedia.org/"
fmt.Println("\n==================================================")
fmt.Println("ğŸš€ Testing web scraper")

fmt.Println("\nğŸŒ Scraping webpage")
fmt.Printf("Fetching: %s\n", testUrl)

var response, err = http.Get(testUrl)
if err != None {
    fmt.Printf("âŒ Error fetching page: %s\n", err)
} else {
    var status = response["status"]
    if status != 200 {
        var statusText = response["statusText"]
        fmt.Printf("âŒ HTTP error: %d %s\n", status, statusText)
    } else {
        var body = response["body"]
        var html, cast_err = cast.ToString(body)
        if cast_err != None {
            fmt.Printf("âŒ Error converting body to string: %s\n", cast_err)
        } else {
            fmt.Printf("âœ… Successfully fetched %d bytes of HTML\n", len(html))
            
            // Extract page title
            fmt.Println("\nğŸ“„ Extracting page title")
            var titleMatches, titleErr = regex.FindStringSubmatch("<title[^>]*>([^<]*)</title>", html)
            if titleErr != None {
                fmt.Printf("âŒ Error extracting title: %s\n", titleErr)
            } else {
                if titleMatches == None {
                    fmt.Println("âŒ No title found")
                } else {
                    if len(titleMatches) > 1 {
                        fmt.Printf("âœ… Title found: '%s'\n", titleMatches[1])
                    } else {
                        fmt.Println("âŒ No title capture group found")
                    }
                }
            }
            
            // Extract first link
            fmt.Println("\nğŸ”— Extracting first link")
            var linkMatches, linkErr = regex.FindStringSubmatch("<a[^>]+href=[\"']([^\"']+)[\"'][^>]*>", html)
            if linkErr != None {
                fmt.Printf("âŒ Error extracting link: %s\n", linkErr)
            } else {
                if linkMatches == None {
                    fmt.Println("âŒ No links found")
                } else {
                    if len(linkMatches) > 1 {
                        fmt.Printf("âœ… Found link: %s\n", linkMatches[1])
                    } else {
                        fmt.Println("âŒ No link capture group found")
                    }
                }
            }
            
            fmt.Println("\nğŸ“Š Scraping Summary:")
            fmt.Println("   ğŸ“„ Page successfully scraped")
            fmt.Println("   ğŸ”— Regex patterns applied")
        }
    }
}

fmt.Println("\n==================================================")
fmt.Println("ğŸ‰ Web scraping example completed!")
fmt.Println("\nğŸ’¡ Tips for production web scraping:")
fmt.Println("   â€¢ Add delays between requests")
fmt.Println("   â€¢ Handle rate limiting and retries")
fmt.Println("   â€¢ Check robots.txt before scraping")
fmt.Println("   â€¢ Use proper User-Agent headers")
